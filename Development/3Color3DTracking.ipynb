{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3-Color 3D TrackMate + Napari Visualization (v 0.4.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is code to analyze 3-color translation movies that have a corresponding track file. The red channel is assumed to be the one corresponding to the tracks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# To manipulate arrays\n",
    "import numpy as np \n",
    "# To import images \n",
    "\n",
    "# To handle track DataFrames\n",
    "import pandas as pd\n",
    "\n",
    "# To import images\n",
    "from skimage import io \n",
    "from skimage.io import imread\n",
    "from skimage import exposure, img_as_uint, img_as_float\n",
    "\n",
    "# To make plots\n",
    "import matplotlib as mpl \n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "# To work inline; change to %matplotlib notebook for interactive plotting\n",
    "%matplotlib inline \n",
    "\n",
    "# Napari \n",
    "%gui qt5 \n",
    "from skimage import data\n",
    "import napari\n",
    "\n",
    "# To create interactive elements\n",
    "import ipywidgets as widgets \n",
    "from ipywidgets import interact, interactive, fixed, interact_manual, Button, HBox, VBox, Layout, GridspecLayout\n",
    "from ipywidgets.embed import embed_minimal_html, dependency_state\n",
    "\n",
    "# Image processing and filters\n",
    "from skimage.filters import difference_of_gaussians\n",
    "\n",
    "# Iteration tools such as groupby \n",
    "import itertools\n",
    "\n",
    "# For directories \n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set current working directory, filenames,  pixel dimensions, and crop size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the current working directory\n",
    "os.chdir('C:/Users/tim_s/OneDrive - Colostate/Stasevich Lab/Lab Management/Dry Lab/Python/Python Scripts/LabScripts/TestData/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set directory of 3D video files and tracking files (must be same):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_directory = 'C:/Users/tim_s/OneDrive - Colostate/Stasevich Lab/Lab Management/Dry Lab/Python/Python Scripts/LabScripts/TestData/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set filename for the video file. Track csv filename must be 'spots in tracks statistics' + filename:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_3D_filename = 'Hela_confocal.tif'\n",
    "#video_3D_filename = '200827_Cont_1_cRNA_cFlag_cGFP.tif'\n",
    "#video_3D_filename = '200827_CA24h_2_cRna_cFlag_cGFP.tiff'\n",
    "video_3D_tracks_filename = 'Spots in tracks statistics_' + video_3D_filename[:-4] + '.csv' \n",
    "video_3D_file_and_path = video_directory + video_3D_filename \n",
    "video_3D_tracks_file_and_path = video_directory +  video_3D_tracks_filename "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the size of the crops you want to use in track array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crop_pad = 5; # size of crops...produces crops of dimensions 2*crop_pad + 1\n",
    "crop_dim = 2*crop_pad + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify X, Y, and Z dimensions of voxels in track array crops or 3D videos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xy_pixel_size, z_pixel_size = 130, 500\n",
    "z_renorm = z_pixel_size/xy_pixel_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load in track csv file into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trackMate = pd.read_csv(video_3D_tracks_file_and_path)\n",
    "trackMate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renormalize the z-position, so tracks appears with proper z-dimension in Napari \n",
    "trackMate['POSITION_Z_Renorm'] = z_renorm*trackMate['POSITION_Z']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful code for sorting tracks by their length...however, incompatible with Napari\n",
    "# g = trackMate.groupby('TRACK_ID')\n",
    "# sg = sorted(g,  # iterates pairs of (key, corresponding subDataFrame)\n",
    "#                 key=lambda x: len(x[1]),  # sort by number of rows (len of subDataFrame)\n",
    "#                 reverse=True)  # reverse the sort i.e. largest first\n",
    "# trackMate=pd.concat([group for name, group in sg])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the TRACK_ID for every unique track\n",
    "myTrackNs=trackMate.TRACK_ID.unique()\n",
    "n_tracks=myTrackNs.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new column in track array with XY positions adjusted for crops (basically make XY middle of crop)\n",
    "trackMate['POSITION_X_CROP']=0*trackMate['POSITION_X']+crop_pad+0.5\n",
    "trackMate['POSITION_Y_CROP']=0*trackMate['POSITION_Y']+crop_pad+0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load in 3D video to make track array (tarpy) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading video as a numpy array\n",
    "video_3D = imread(video_3D_filename)\n",
    "#video_3D = imread('200827_Cont_1_cRNA_cFlag_cGFP.tif')\n",
    "#video_3D = imread('200827_CA24h_2_cRna_cFlag_cGFP.tiff')\n",
    "#video_3D = imread('E:/Tim_tracking videos_all zs/TA02_90m.tif')\n",
    "n_frames = video_3D.shape[0]\n",
    "z_slices = video_3D.shape[1]\n",
    "height_y = video_3D.shape[2]\n",
    "width_x = video_3D.shape[3]\n",
    "n_channels = video_3D.shape[4]\n",
    "video_3D.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find nice intensity ranges for display later; tracks assumed to be red channel\n",
    "allr = np.ma.masked_equal(video_3D[:,:,:,:,0],0).compressed().flatten() # Drop zeros\n",
    "allg = np.ma.masked_equal(video_3D[:,:,:,:,1],0).compressed().flatten() # Drop zeros\n",
    "allb = np.ma.masked_equal(video_3D[:,:,:,:,2],0).compressed().flatten() # Drop zeros\n",
    "r_range = [np.mean(trackMate['MIN_INTENSITY'])/1.5,1.5*np.mean(trackMate['MAX_INTENSITY'])]\n",
    "g_range = [np.median(allg)-0.1*np.std(allg),np.median(allg)+7*np.std(allg)]\n",
    "b_range = [np.median(allb)-0.1*np.std(allb),np.median(allb)+7*np.std(allb)]\n",
    "range = (np.min([r_range[0], g_range[0], b_range[0]]), np.max([r_range[1], g_range[1], b_range[1]]))\n",
    "n, bins, patches = plt.hist(allr, 100,range,edgecolor='r',histtype='step')\n",
    "n, bins, patches = plt.hist(allg, 100, range,edgecolor='g', histtype='step')\n",
    "n, bins, patches = plt.hist(allb, 100, range,edgecolor='b',histtype='step')\n",
    "plt.xlabel('Background Subtracted Intensity')\n",
    "plt.ylabel('Number')\n",
    "plt.title('Histogram of Intensities')\n",
    "plt.grid(True)\n",
    "#plt.xlim(0, np.max([r_range[1], g_range[1], b_range[1]]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize tracks in original 4D image with Napari (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up tracks in Napari format for viewing\n",
    "trackMate_napari=trackMate[['TRACK_ID','POSITION_T','POSITION_Z_Renorm','POSITION_Y','POSITION_X']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##Comment/uncomment this using Ctrl + 'a' to select all and then Ctrl + 'l' to uncomment/comment\n",
    "# # View in Napari using tracks layer:\n",
    "# viewer = napari.Viewer()\n",
    "# viewer.add_image(video_3D[:, :, :, :, 0], colormap='red',\n",
    "#                  name='red',blending=\"additive\", scale=[1, z_renorm, 1, 1],\n",
    "#                  contrast_limits=r_range)\n",
    "# viewer.add_image(video_3D[:, :, :, :, 1], colormap='green',\n",
    "#                  name='green',blending=\"additive\", scale=[1, z_renorm, 1, 1],\n",
    "#                  contrast_limits=g_range)\n",
    "# viewer.add_image(video_3D[:, :, :, :, 2], colormap='blue',\n",
    "#                  name='blue',blending=\"additive\", scale=[1, z_renorm, 1, 1],\n",
    "#                  contrast_limits=b_range)\n",
    "# viewer.add_tracks(trackMate_napari.values, tail_width = 3, tail_length=25, name=\"my_tracks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making and exploring an array of 4D track crops using Napari "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is an empty array that will hold ALL the crops of each track\n",
    "myCropsAll=np.zeros((n_tracks,n_frames,z_slices,2*crop_pad+1,2*crop_pad+1,n_channels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign each crop to empty array defined above\n",
    "myi=0\n",
    "for myN in myTrackNs:\n",
    "    myTrack = trackMate[(trackMate['TRACK_ID'] == myN) & (trackMate['POSITION_X']<width_x-crop_pad-1) & (trackMate['POSITION_X']>crop_pad+1) & (trackMate['POSITION_Y']<height_y-crop_pad-1) & (trackMate['POSITION_Y']>crop_pad+1) ]\n",
    "    myTimes=myTrack['POSITION_T'].values.astype(int) \n",
    "    myX=myTrack['POSITION_X'].round(0).values.astype(int)\n",
    "    myY=myTrack['POSITION_Y'].round(0).values.astype(int)\n",
    "    myZ=myTrack['POSITION_Z'].round(0).values.astype(int)\n",
    "    myTrack_napari = myTrack[['TRACK_ID','POSITION_T','POSITION_Z_Renorm','POSITION_Y_CROP','POSITION_X_CROP']]\n",
    "    tind = 0\n",
    "    for t in myTimes:\n",
    "        myCropsAll[myi,t,:,:,:,:] = video_3D[t,:,myY[tind]-crop_pad:myY[tind]+crop_pad+1,myX[tind]-crop_pad:myX[tind]+crop_pad+1,:]\n",
    "        tind = tind + 1\n",
    "    myi = myi+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # View in Napari; track layer doesn't work in this format\n",
    "# viewer = napari.Viewer()\n",
    "# viewer.add_image(myCropsAll[:, :, :, :, :, 0], colormap='red',\n",
    "#                  name='red',blending=\"additive\", scale=[1, 1, z_renorm, 1, 1],\n",
    "#                  contrast_limits=r_range)\n",
    "# viewer.add_image(myCropsAll[:, :, :, :, :, 1], colormap='green',\n",
    "#                  name='green',blending=\"additive\", scale=[1, 1, z_renorm, 1, 1],\n",
    "#                  contrast_limits=g_range)\n",
    "# viewer.add_image(myCropsAll[:, :, :, :, :, 2], colormap='blue',\n",
    "#                  name='blue',blending=\"additive\", scale=[1,1, z_renorm, 1, 1],\n",
    "#                  contrast_limits=b_range)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving track array (tarpy) as video_3D_tracks_filename + crop_pad + '.tif'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save our multicolour stack to a new ImageJ-compatible TIF file\n",
    "# tifffile wants our array to be in TZCYXS order for imageJ compatibility\n",
    "myCropsAll4D = np.hstack(myCropsAll.swapaxes(2,4)).swapaxes(1,3)\n",
    "myCropsAll4D_Z = np.hstack(myCropsAll4D).swapaxes(1,2)\n",
    "my4DArray = np.moveaxis(myCropsAll4D_Z.astype(np.int16),-1,1) \n",
    "io.imsave(video_directory + video_3D_tracks_filename[:-4] + '_crop_pad_' + str(crop_pad) + '.tif',\n",
    "        my4DArray,  # so move C from the end to second dimension\n",
    "        imagej=True,\n",
    "        resolution=(1/xy_pixel_size,1/xy_pixel_size),  # store x and y resolution in pixels/nm\n",
    "        metadata={'spacing':z_pixel_size,'unit':'nm'})  # store z spaxing in nm and set units to nm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading in track array (tarpy)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Quick check that there is no loss of data when reading out and reading back in\n",
    "video_tarpy_filename = video_3D_tracks_filename[:-4] + '_crop_pad_' + str(crop_pad) + '.tif'\n",
    "video_tarpy_filename_and_path = video_directory + video_tarpy_filename\n",
    "video_tarpy = imread(video_tarpy_filename_and_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = video_tarpy_filename.find('crop_pad_')\n",
    "s2 = video_tarpy_filename.find('.tif')\n",
    "crop_pad = int(video_tarpy_filename[s1+9:s2])\n",
    "crop_dim = 2*crop_pad+1\n",
    "n_frames = int(video_tarpy.shape[2]/crop_dim)\n",
    "z_slices = int(video_tarpy.shape[0])\n",
    "n_channels = int(video_tarpy.shape[3])\n",
    "n_tracks = int(video_tarpy.shape[1]/crop_dim)\n",
    "[video_tarpy.shape, n_frames, z_slices, n_channels, n_tracks, crop_dim, z_renorm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recreate myCropsAll array from tarpy\n",
    "myCropsAll = np.zeros((n_tracks,n_frames,z_slices,crop_dim,crop_dim,n_channels))\n",
    "for n in np.arange(n_tracks):\n",
    "    for t in np.arange(n_frames):\n",
    "        myCropsAll[n,t] = video_tarpy[:,n*crop_dim:n*crop_dim+crop_dim,t*crop_dim:t*crop_dim+crop_dim,:]\n",
    "myCropsAll = np.swapaxes(myCropsAll,3,4)  # Must swap x and y after imread so it matches what we saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Make a napari track label dataframe to see which track is which during visualization of track array\n",
    "zeros = np.zeros(n_tracks)\n",
    "step = 2*crop_pad+1\n",
    "myLabelTrackXDF=pd.DataFrame(np.array([myTrackNs, zeros, zeros, zeros, np.arange(crop_pad, step*myTrackNs.size, step)]).T,\n",
    "                            columns=['TRACK_ID', 'POSITION_T', 'POSITION_Z', 'POSITION_Y', 'POSITION_X'])\n",
    "myLabelTrackYDF=pd.DataFrame(np.array([myTrackNs, zeros, zeros, np.arange(crop_pad, step*myTrackNs.size, step),zeros]).T,\n",
    "                            columns=['TRACK_ID', 'POSITION_T', 'POSITION_Z', 'POSITION_Y', 'POSITION_X'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find nice intensity ranges for display later; tracks assumed to be red channel\n",
    "allr = np.ma.masked_equal(video_tarpy[:,:,:,0],0).compressed().flatten() # Drop zeros\n",
    "allg = np.ma.masked_equal(video_tarpy[:,:,:,1],0).compressed().flatten() # Drop zeros\n",
    "allb = np.ma.masked_equal(video_tarpy[:,:,:,2],0).compressed().flatten() # Drop zeros\n",
    "r_range = [np.mean(trackMate['MIN_INTENSITY'])/1.5,1.5*np.mean(trackMate['MAX_INTENSITY'])]\n",
    "g_range = [np.median(allr)-3*np.std(allr),np.median(allg)+8*np.std(allg)]\n",
    "b_range = [np.median(allr)-3*np.std(allr),np.median(allb)+8*np.std(allb)]\n",
    "range = (np.min([r_range[0], g_range[0], b_range[0]]), np.max([r_range[1], g_range[1], b_range[1]]))\n",
    "n, bins, patches = plt.hist(allr, 100,range,edgecolor='r',histtype='step')\n",
    "n, bins, patches = plt.hist(allg, 100, range,edgecolor='g', histtype='step')\n",
    "n, bins, patches = plt.hist(allb, 100, range,edgecolor='b',histtype='step')\n",
    "plt.xlabel('Background Subtracted Intensity')\n",
    "plt.ylabel('Number')\n",
    "plt.title('Histogram of Intensities')\n",
    "plt.grid(True)\n",
    "#plt.xlim(0, np.max([r_range[1], g_range[1], b_range[1]]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # View in Napari; track layer doesn't work in this format\n",
    "# imgr, imgg, imgb = video_tarpy[:,:,:,0], video_tarpy[:,:,:,1], video_tarpy[:,:,:,2]\n",
    "# viewer = napari.Viewer()\n",
    "# viewer.add_image(imgr, colormap='red',\n",
    "#                  name='red',blending=\"additive\", scale=[z_renorm, 1, 1],\n",
    "#                  contrast_limits=r_range)\n",
    "# viewer.add_image(imgg, colormap='green',\n",
    "#                  name='green',blending=\"additive\", scale=[z_renorm, 1, 1],\n",
    "#                  contrast_limits=g_range)\n",
    "# viewer.add_image(imgb, colormap='blue',\n",
    "#                  name='blue',blending=\"additive\", scale=[z_renorm, 1, 1],\n",
    "#                  contrast_limits=b_range)\n",
    "# viewer.add_tracks(myLabelTrackYDF.values, tail_width = 7, tail_length=50, name=\"labels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions for making track array 3D masks for analysis and visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some functions to make useful 3D masks for quantifying signal intensities\n",
    "\n",
    "# A cuboid array centered at (cx,cy,cz) with half-lengths (rx,ry,rz) in a volumeXYZ\n",
    "def myCuboid(cx,cy,cz,rx,ry,rz,volumeX, volumeY, volumeZ):\n",
    "    x = np.arange(0, volumeX)\n",
    "    y = np.arange(0, volumeY)\n",
    "    z = np.arange(0, volumeZ)\n",
    "    arr = np.zeros((z.size, y.size, x.size))\n",
    "    stripx = np.heaviside(x[np.newaxis,np.newaxis,:]-(cx-rx),1)-np.heaviside(x[np.newaxis,np.newaxis,:]-(cx+rx+1),1)\n",
    "    stripy = np.heaviside(y[np.newaxis,:,np.newaxis]-(cy-ry),1)-np.heaviside(y[np.newaxis,:,np.newaxis]-(cy+ry+1),1)\n",
    "    stripz = np.heaviside(z[:,np.newaxis,np.newaxis]-(cz-rz),1)-np.heaviside(z[:,np.newaxis,np.newaxis]-(cz+rz+1),1)\n",
    "    mask = stripx*stripy*stripz\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A ellipsoid centered at (cx,cy,cz) with semi-axes of rx, ry, and rz in volumeXYZ\n",
    "# This is basically the 3D version of the 'disk' in disk-donut quantification\n",
    "def myCigar(cx,cy,cz,rx,ry,rz,volumeX, volumeY, volumeZ):\n",
    "    x = np.arange(0, volumeX)\n",
    "    y = np.arange(0, volumeY)\n",
    "    z = np.arange(0, volumeZ)\n",
    "    arr = np.zeros((z.size, y.size, x.size))\n",
    "    mask = ((1/rx)**2)*(x[np.newaxis,np.newaxis,:]-cx)**2 + ((1/ry)**2)*(y[np.newaxis,:,np.newaxis]-cy)**2 + ((1/rz)**2)*(z[:,np.newaxis,np.newaxis]-cz)**2 < 1\n",
    "    arr[mask] = 1.\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A capsule that surrounds myCigar(cx,cy,cz,rx,ry,rz,volumeX, volumeY, volumeZ)\n",
    "# This is basically the 3D version of the 'donut' in 'disk-donut' quantification\n",
    "def myCapsule(cx,cy,cz,rx,ry,rz,volumeX,volumeY,volumeZ):\n",
    "    arr1=myCigar(cx,cy,cz,rx+1,ry+1,rz+1,volumeX, volumeY, volumeZ)\n",
    "    arr2=myCigar(cx,cy,cz,rx+2,ry+2,rz+2,volumeX, volumeY, volumeZ)\n",
    "    return arr2-arr1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Below we test what these look like in 3D. \n",
    "#     # The cuboid shows the volume that would correspond to one 3D crop.\n",
    "#     # The cigar shows the volume in which signal would be quantified\n",
    "#     # The capsule shows the volume in which background would be quantified\n",
    "# viewer = napari.Viewer()\n",
    "# viewer.add_image(myCuboid(10,10,10,5,5,3,20,20,20), colormap='red',\n",
    "#                  name='red',blending=\"additive\", scale=[z_renorm,1, 1])\n",
    "# viewer.add_image(myCapsule(10,10,10,4,4,2,20,20,20), colormap='green',\n",
    "#                  name='green',blending=\"additive\", scale=[z_renorm,1, 1])\n",
    "# viewer.add_image(myCigar(10,10,10,4,4,2,20,20,20), colormap='blue',\n",
    "#                  name='blue',blending=\"additive\", scale=[z_renorm,1, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making unique 3D masks for every crop in dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make empty arrays to hold all the arrays of various types of masks \n",
    "myCigarMasksAll = np.zeros((n_tracks,n_frames,z_slices,2*crop_pad+1,2*crop_pad+1))\n",
    "myCapsuleMasksAll = np.zeros((n_tracks,n_frames,z_slices,2*crop_pad+1,2*crop_pad+1))\n",
    "myBestZMasksAll = np.zeros((n_tracks,n_frames,z_slices,2*crop_pad+1,2*crop_pad+1))\n",
    "\n",
    "# Loop function over all crops to find best-Z plane and make a custom mask\n",
    "for n in np.arange(n_tracks):\n",
    "    for t in np.arange(n_frames):\n",
    "        curCrop = myCropsAll[n,t,:,crop_pad-1:crop_pad+2,crop_pad-1:crop_pad+2,0]\n",
    "        myCenterZ = np.argmax(np.mean(difference_of_gaussians(curCrop,1,7),axis=(1,2))) # Find Z with the max average intensity in a central 3x3 square after applying bandpass filter\n",
    "        myCigarMasksAll[n,t] = myCigar(crop_pad,crop_pad,myCenterZ,2,2,2,int(2*crop_pad+1),int(2*crop_pad+1),z_slices)\n",
    "        myCapsuleMasksAll[n,t] = myCapsule(crop_pad,crop_pad,myCenterZ,2,2,2,int(2*crop_pad+1),int(2*crop_pad+1),z_slices)\n",
    "        myBestZMasksAll[n,t] = myCuboid(crop_pad,crop_pad,myCenterZ,5,5,1,2*crop_pad+1,2*crop_pad+1,z_slices)\n",
    "# Make RGB color versions of each mask\n",
    "myCigarMasksAllRGB = np.array([myCigarMasksAll,myCigarMasksAll,myCigarMasksAll]).transpose(1,2,3,4,5,0)\n",
    "myCapsuleMasksAllRGB = np.array([myCapsuleMasksAll,myCapsuleMasksAll,myCapsuleMasksAll]).transpose(1,2,3,4,5,0)\n",
    "myBestZMasksAllRGB = np.array([myBestZMasksAll,myBestZMasksAll,myBestZMasksAll]).transpose(1,2,3,4,5,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring all track crops, masks, and projections with Napari"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Various projections and visualizations for checking everything\n",
    "myCropsAll4D = np.hstack(myCropsAll.swapaxes(2,4)).swapaxes(1,3)\n",
    "myCigarMasksAll4D = np.hstack(myCigarMasksAll.swapaxes(2,4)).swapaxes(1,3)\n",
    "myBestZMasksAll4D = np.hstack(myBestZMasksAll.swapaxes(2,4)).swapaxes(1,3)\n",
    "myCropsAll4D_Z = np.hstack(myCropsAll4D).swapaxes(1,2)\n",
    "myCigarMasksAll4D_Z = np.hstack(myCigarMasksAll4D).swapaxes(1,2)\n",
    "myBestZMasksAll4D_Z = np.hstack(myBestZMasksAll4D).swapaxes(1,2)\n",
    "myCropsAll4D_T = np.hstack(myCropsAll4D.swapaxes(0,1))\n",
    "myCigarMasksAll4D_T = np.hstack(myCigarMasksAll4D.swapaxes(0,1))\n",
    "myCropsAll4D_SP = np.hstack((myCropsAll*myBestZMasksAllRGB).swapaxes(2,4)).swapaxes(1,3)\n",
    "myCropsAll3D_SP_Z = np.amax(np.hstack(myCropsAll4D_SP).swapaxes(1,2),0)\n",
    "myCropsAll3D_SP_Z_MaxZ = np.amax(myCropsAll*myBestZMasksAllRGB,2)\n",
    "myCropsAll3D_SP_Z_MaxZ_Mask = np.amax(myBestZMasksAllRGB,2)\n",
    "myCropsAll3D_SP_T=np.amax((myCropsAll4D_T),0) #max T projection \n",
    "myCropsAll2D_XT = np.amax(np.amax(myCropsAll4D_SP,1),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# View in Napari\n",
    "def myNapariViewer(viewChoice = 'N x T Grid of Smart-Z projections'):\n",
    "    \n",
    "    if viewChoice == 'N x 1 Row of Crops; Scroll Z & T':\n",
    "        myR, myG, myB = myCropsAll4D[:,:,:,:,0], myCropsAll4D[:,:,:,:,1], myCropsAll4D[:,:,:,:,2]\n",
    "        myScale = [1, z_renorm, 1, 1]\n",
    "        myLayer = myCigarMasksAll4D ## Could also be myBestZMaskAll4D\n",
    "        myLabel = myLabelTrackXDF.values \n",
    "    \n",
    "    if viewChoice == 'N x T Grid of Crops; Scroll Z':\n",
    "        myR, myG, myB = myCropsAll4D_Z[:,:,:,0], myCropsAll4D_Z[:,:,:,1], myCropsAll4D_Z[:,:,:,2]\n",
    "        myScale = [z_renorm,1,1]\n",
    "        myLayer = myCigarMasksAll4D_Z \n",
    "        myLabel = myLabelTrackYDF.values\n",
    "    \n",
    "    if viewChoice == 'N x Z Grid of Crops; Scroll T': # easy to check masks!\n",
    "        myR, myG, myB = myCropsAll4D_T[:,:,:,0], myCropsAll4D_T[:,:,:,1], myCropsAll4D_T[:,:,:,2]\n",
    "        myScale = [1,1,1]\n",
    "        myLayer = myCigarMasksAll4D_T ## Could also be myBestZMaskAll4D\n",
    "        myLabel = myLabelTrackXDF.values\n",
    "    \n",
    "    if viewChoice == 'N x T Grid of Smart-Z projections':  # Best visualization\n",
    "        myR, myG, myB = myCropsAll3D_SP_Z[:,:,0], myCropsAll3D_SP_Z[:,:,1], myCropsAll3D_SP_Z[:,:,2]\n",
    "        myScale = [1,1]\n",
    "        myLayer = myCigarMasksAll4D_Z  \n",
    "        myLabel = myLabelTrackYDF.values\n",
    "    \n",
    "    if viewChoice == 'X x Y x T image; Scroll tracks':  # Cool visualization; High-content\n",
    "        myR, myG, myB = myCropsAll3D_SP_Z_MaxZ[:,:,:,:,0], myCropsAll3D_SP_Z_MaxZ[:,:,:,:,1], myCropsAll3D_SP_Z_MaxZ[:,:,:,:,2]\n",
    "        myScale = [1,1,1,1]\n",
    "        myLayer = myCropsAll3D_SP_Z_MaxZ_Mask\n",
    "        myLabel=np.array([[0,0,0,0,0]])  # Dummy array...don't really need label for this one\n",
    "\n",
    "    if viewChoice == 'N x Z grid of max T projection':\n",
    "        myR, myG, myB = myCropsAll3D_SP_T[:,:,0], myCropsAll3D_SP_T[:,:,1], myCropsAll3D_SP_T[:,:,2]\n",
    "        myScale = [1,1]\n",
    "        myLayer = myCigarMasksAll4D_T \n",
    "        myLabel = myLabelTrackXDF.values\n",
    "\n",
    "    if viewChoice == 'N x 1 grid of max XT images':\n",
    "        myR, myG, myB = myCropsAll2D_XT[:,:,0], myCropsAll2D_XT[:,:,1], myCropsAll2D_XT[:,:,2]\n",
    "        myScale = [1,1]\n",
    "        myLayer = myCigarMasksAll4D_T \n",
    "        myLabel = myLabelTrackXDF.values\n",
    "\n",
    "    # Napari Visualization: \n",
    "    viewer = napari.Viewer()\n",
    "    viewer.add_image(myR, colormap='red',\n",
    "                 name='red',blending=\"additive\", scale=myScale,\n",
    "                 contrast_limits=r_range)\n",
    "    viewer.add_image(myG, colormap='green',\n",
    "                 name='green',blending=\"additive\", scale=myScale,\n",
    "                 contrast_limits=b_range)\n",
    "    viewer.add_image(myB, colormap='blue',\n",
    "                 name='blue',blending=\"additive\", scale=myScale,\n",
    "                 contrast_limits=g_range)\n",
    "    viewer.add_image(myLayer, colormap='gray',opacity=0.25,\n",
    "                 name='layer',blending=\"additive\", scale=myScale)\n",
    "    viewer.add_tracks(myLabel, tail_width = 7, tail_length=50, name=\"labels\")\n",
    "    \n",
    "interact(myNapariViewer, viewChoice=['N x 1 Row of Crops; Scroll Z & T',\n",
    "                                     'N x T Grid of Crops; Scroll Z',\n",
    "                                     'N x Z Grid of Crops; Scroll T',\n",
    "                                     'N x T Grid of Smart-Z projections',\n",
    "                                     'X x Y x T image; Scroll tracks',\n",
    "                                     'N x Z grid of max T projection',\n",
    "                                     'N x 1 grid of max XT images'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data quantification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepare Data for Cropping using 3D masked crops (can choose)\n",
    "\n",
    "#Option 1: Cigar-capsule quantification (\n",
    "mySigMask, myBGMask = myCigarMasksAllRGB ,myCapsuleMasksAllRGB \n",
    "\n",
    "#Option 2: Cylinder-ring quantification \n",
    "#Need to write this still\n",
    "\n",
    "mySig=np.mean(np.ma.masked_equal(mySigMask*myCropsAll,0),axis=(2,3,4)) # Mean on Masked crops\n",
    "myBG=np.mean(np.ma.masked_equal(myBGMask*myCropsAll,0),axis=(2,3,4)) # Mean on Masked crops\n",
    "myInt=mySig.data-myBG.data  # get unmasked data out of masked array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the histogram of the data\n",
    "allr=np.ma.masked_equal(myInt[:,:,0],0).compressed().flatten() # Drop zeros\n",
    "allg=np.ma.masked_equal(myInt[:,:,1],0).compressed().flatten() # Drop zeros\n",
    "allb=np.ma.masked_equal(myInt[:,:,2],0).compressed().flatten() # Drop zeros\n",
    "n, bins, patches = plt.hist(allr, 50, (-400, 600),edgecolor='r',histtype='step')\n",
    "n, bins, patches = plt.hist(allg, 50, (-400, 600), edgecolor='g', histtype='step')\n",
    "n, bins, patches = plt.hist(allb, 50,(-400, 600), edgecolor='b',histtype='step')\n",
    "plt.xlabel('Background Subtracted Intensity')\n",
    "plt.ylabel('Number')\n",
    "plt.title('Histogram of Intensities')\n",
    "plt.grid(True)\n",
    "plt.xlim(-400, 600)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myIntPlotter(myTOI):\n",
    "    t = np.arange(n_frames)\n",
    "    r = np.ma.masked_equal(myInt[myTOI,:,0],0)  # Red channel; mask zeros (skipped frames in tracks)\n",
    "    g = np.ma.masked_equal(myInt[myTOI,:,1],0) #np.ma.masked_equal(myInt[myTOI,:,1],0)  # Green channel; mask zeros\n",
    "    b = np.ma.masked_equal(myInt[myTOI,:,2],0) #np.ma.masked_equal(myInt[myTOI,:,2],0)  # Blue channel; mask zeros\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(t, r,'ro-',g,'gs-',b,'b^-')\n",
    "    ax.set(xlabel='frame #', ylabel='Intensity (a.u.)',\n",
    "       title='Track Intensity vs. time')\n",
    "    ax.grid()\n",
    "    plt.show()\n",
    "    print(\"TrackMate ID is %d.\" % myTrackNs[myTOI])\n",
    "interact(myIntPlotter, myTOI=(0,myInt.shape[0]-1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identifying translation spots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will count how many times the green intensity is above myIntThreshhold  \n",
    "# for a continuous run of length myRunLength. The total length of such continuous\n",
    "# runs is calculated\n",
    "myIntThreshhold = 50   # Set this based on intensity histogram above\n",
    "myRunLength = 4\n",
    "myID = np.zeros(myInt.shape[0])    # an array to hold the counts\n",
    "\n",
    "for i in np.arange(myInt.shape[0]):    # going one track at a time\n",
    "    s=np.where(myInt[i,:,1] > myIntThreshhold, 1, 0) # 1 if > threshhold, 0 otherwise \n",
    "    # Below will create a list of continuous runs of 1s (Int>100) and 0s (Int<100)\n",
    "    full_listing = [(a, list(b)) for a, b in itertools.groupby(s)]\n",
    "    # Only take the continuous runs of 1s (Int>100)\n",
    "    all_runs = [b for a, b in full_listing if a == 1]\n",
    "    # Cacluate the length of each of these runs\n",
    "    long_run_lengths=[len(a) for a in all_runs if len(a)>=myRunLength]  # could improve?\n",
    "    # Ouput the sum of the lengths of each continous run\n",
    "    myID[i] = sum(long_run_lengths)\n",
    "    \n",
    "# Now count how many times the runs are longer than myRunLength   \n",
    "translatingSpots0 = np.where(myID > myRunLength)[0]\n",
    "translatingSpots = myTrackNs[translatingSpots0]\n",
    "# Translating spot IDs and the fraction of spots that are translating \n",
    "[translatingSpots, translatingSpots.size,translatingSpots.size/myID.size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checked by eye using Napari visualization above for Hela_confocal.tif\n",
    "# Maybes by eye: 28, 57, 58,100\n",
    "translatingSpotsByEye=np.array([  8,   9,  10,  11,  14,  17,  43,  51,  67,  68,  70,  91,  94,\n",
    "         98, 100, 102, 108, 184, 223, 231, 255, 263, 300])\n",
    "[translatingSpotsByEye, translatingSpotsByEye.size, translatingSpotsByEye.size/myID.size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate what fraction the algorithm guessed correctly\n",
    "intersect = [ i for i in translatingSpots if i in translatingSpotsByEye] \n",
    "complement = [ i for i in translatingSpots  if i not in translatingSpotsByEye] \n",
    "complement2 = [ i for i in translatingSpotsByEye  if i not in translatingSpots] \n",
    "np.array([intersect,complement,complement2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[len(intersect)/translatingSpotsByEye.size,  # fraction of real spots dectected\n",
    "len(complement)/translatingSpots.size]       # fraction of spots that might be false positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myCropsAll[translatingSpots0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking predicted translating and non-translating tracks by eye"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check by eye...algorithm finds many translating spots that check out upon inspection\n",
    "mySpots=translatingSpots0 # translating indices\n",
    "#mySpots=np.array([i for i in np.arange(myTrackNs.size) if i not in translatingSpots0])# non-translating indices\n",
    "zeros = np.zeros(myTrackNs[mySpots].size)\n",
    "step = 2*crop_pad+1\n",
    "myLabelTrackYDF2=pd.DataFrame(np.array([myTrackNs[mySpots], zeros, zeros, \n",
    "                                    np.arange(crop_pad, step*mySpots.size, step),zeros]).T,\n",
    "                            columns=['TRACK_ID', 'POSITION_T', 'POSITION_Z', 'POSITION_Y', 'POSITION_X'])\n",
    "myCropsAll4D_SP = np.hstack((myCropsAll[mySpots]*myBestZMasksAllRGB[mySpots]).swapaxes(2,4)).swapaxes(1,3)\n",
    "myCropsAll3D_SP_Z = np.amax(np.hstack(myCropsAll4D_SP).swapaxes(1,2),0)\n",
    "myCigarMasksAll4D_Z = np.hstack(myCigarMasksAll4D).swapaxes(1,2)\n",
    "myR, myG, myB = myCropsAll3D_SP_Z[:,:,0], myCropsAll3D_SP_Z[:,:,1], myCropsAll3D_SP_Z[:,:,2]\n",
    "myScale = [1,1]\n",
    "myLayer = myCigarMasksAll4D_Z  \n",
    "myLabel = myLabelTrackYDF2\n",
    "viewer = napari.Viewer()\n",
    "viewer.add_image(myR, colormap='red',\n",
    "                 name='red',blending=\"additive\", scale=myScale,\n",
    "                 contrast_limits=r_range)\n",
    "viewer.add_image(myG, colormap='green',\n",
    "                 name='green',blending=\"additive\", scale=myScale,\n",
    "                 contrast_limits=g_range)\n",
    "viewer.add_image(myB, colormap='blue',\n",
    "                 name='blue',blending=\"additive\", scale=myScale,\n",
    "                 contrast_limits=b_range)\n",
    "#viewer.add_image(myLayer, colormap='gray',opacity=0.25,\n",
    "#                 name='layer',blending=\"additive\", scale=myScale)\n",
    "viewer.add_tracks(myLabel, tail_width = 7, tail_length=50, name=\"labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hela\n",
    "# Periodicity?: 11, 24, 25, 33, 41, 48, 50, 53, 56, 70, 71, 82\n",
    "\n",
    "# Control \n",
    "# 26% translating according to algorithm\n",
    "# Local translation! See 43, 119, **184, 342, 527\n",
    "# false positive: 168, 191, 235, 1255\n",
    "# need better tracking: 986,1018\n",
    "\n",
    "# CA24 hrs\n",
    "# 21% translating according to algorithm\n",
    "# Seems less obvious translation...\n",
    "# More false positive"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
