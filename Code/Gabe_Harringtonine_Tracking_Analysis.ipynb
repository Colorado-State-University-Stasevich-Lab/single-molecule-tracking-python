{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#os.chdir('C:/Users/tim_s/OneDrive - Colostate/Stasevich Lab/Lab Management/Dry Lab/Python/Python Scripts/LabScripts')\n",
    "# To manipulate arrays\n",
    "import numpy as np \n",
    "# To import images \n",
    "\n",
    "# To handle track DataFrames\n",
    "import pandas as pd\n",
    "\n",
    "# To import images\n",
    "from skimage import io \n",
    "from skimage.io import imread\n",
    "\n",
    "# For TrackPy\n",
    "import trackpy as tp\n",
    "\n",
    "# To make plots\n",
    "import matplotlib as mpl \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns; sns.set()  \n",
    "\n",
    "# To work inline; change to %matplotlib notebook for interactive plotting\n",
    "%matplotlib inline \n",
    "\n",
    "# Napari \n",
    "%gui qt5 \n",
    "from skimage import data\n",
    "import napari\n",
    "\n",
    "# To create interactive elements\n",
    "import ipywidgets as widgets \n",
    "from ipywidgets import interact, interactive, fixed, interact_manual, Button, HBox, VBox, Layout, GridspecLayout\n",
    "from ipywidgets.embed import embed_minimal_html, dependency_state\n",
    "\n",
    "# Image processing and filters\n",
    "from skimage.filters import difference_of_gaussians\n",
    "\n",
    "# Iteration tools such as groupby \n",
    "import itertools\n",
    "\n",
    "# For directories \n",
    "import os\n",
    "\n",
    "# For reloading a library when testing\n",
    "import importlib\n",
    "\n",
    "# For deleting/reloading modules in another file for code testing\n",
    "import sys\n",
    "\n",
    "# For statistics\n",
    "from scipy import stats\n",
    "\n",
    "# For curve fitting\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "# Seaborn plotting\n",
    "import seaborn as sns\n",
    "\n",
    "# Import trackArrayTools\n",
    "from trackArrayTools import *\n",
    "\n",
    "# Import for correlation analysis\n",
    "from scipy import signal\n",
    "\n",
    "#rSNAPsim_IP\n",
    "#cwd = os.getcwd()  # get current working director\n",
    "#os.chdir('../rSNAPsim_IP/rSNAPsim_IP/') # assume rSNAPsim_IP is  one directory up\n",
    "#import rSNAPsim_IP as rss_IP #importing rSNAPsim.\n",
    "#os.chdir(cwd) # change back to original current directory (the directory this file is in)\n",
    "\n",
    "#del sys.modules['trackArrayTools']  # Use this if you are coding new class methods and want to reread trackArrayTools.py file\n",
    "#from trackArrayTools import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set current working directory, track array filenames, and basic parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Enter in the following:\n",
    "crop_pad = 5    # specifies the size of crops in track arary. If 5, then crops are (2*5 + 1 = 11) x 11\n",
    "xy_pixel_size = 130   # voxel  xy dimensions in crops\n",
    "z_pixel_size = 500   # voxel z dimension\n",
    "working_directory = 'C:/Users/tim_s/OneDrive - Colostate/Stasevich Lab/Our papers/Ago2Tethering/TimFastTrackAnalysis/'\n",
    "video_3D_filename_path = 'C:/Users/tim_s/Documents/Python Scripts/LabScripts/TestData/'\n",
    "#beads_path = 'X:/_FiXie/Charlotte/_90m movies for particle tracking/20180707_TA_translation assay_90m images/Beads/'\n",
    "video_3D_filename = 'TA02_90m.tif'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Tracks_TA02_90m_crop_pad_5.tif', 'Tracks_TA02_90m.csv']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For display, so z and xy are shown properly when viewing track array\n",
    "z_renorm = z_pixel_size/xy_pixel_size  \n",
    "\n",
    "#  Track array filenames should be the following:\n",
    "track_array_filename = 'Tracks_' + video_3D_filename[:-4] + '_crop_pad_' + str(crop_pad) + '.tif' \n",
    "track_filename = track_array_filename[:-15] + '.csv'\n",
    "[track_array_filename, track_filename]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Track Array (only done once using original 3D video and tracks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# # Loading the figure with beads so track array can be registered\n",
    "# # Dimension 1 is the number of channel. Red and Green. # Dimension 2 is the x axis. # Dimension 3 is the y axis.\n",
    "# figWithBeads = beads_path + 'Beads01.tif'\n",
    "# im_beads = io.imread(figWithBeads) # reading the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# # Using rSNAPSim to get the homography matrix to align the green/blue channels with red\n",
    "# #temp_obj_beads = rss_IP.BeadsAlignment(im_beads)\n",
    "# [my_homography,positions_green,positions_red] = temp_obj_beads.make_beads_alignment()  # !!! Adjusted Luis' code to spit this info out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Check that the homography matrix is working:\n",
    "#my_homography_inverse = np.linalg.inv(my_homography)  # This is the transformation we use to shift green to red\n",
    "#print('[original distance, corrected distance (shift red to green), corrected distance (shift green to red)]' )\n",
    "#for i in np.arange(len(positions_green)):\n",
    "#     g0=positions_green[i]\n",
    "#     g=np.dot(my_homography_inverse,[positions_green[i,0],positions_green[i,1],1])[0:2]  # Correct green/blue\n",
    "#     r0=positions_red[i]\n",
    "#     r=np.dot(my_homography,[positions_red[i,0],positions_red[i,1],1])[0:2]  # What you'll do: shift red to green\n",
    "#     print([np.linalg.norm(g0-r0),np.linalg.norm(g0-r),np.linalg.norm(g-r0)]) # Check corrections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Read in the original 3D video \n",
    "video_3D = imread(video_3D_filename_path+video_3D_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Read in the tracking file that corresponds to the original 3D video\n",
    "tracks = pd.read_csv(video_3D_filename_path+track_filename) \n",
    "# tracks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Tracks layer 'TRACK_IDs' at 0x2005a7a3d88>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "viewer = napari.Viewer()\n",
    "viewer.add_image(video_3D[:,:,:,:,0],name='red',colormap = 'red',blending=\"additive\", scale=[z_renorm,1,1])\n",
    "viewer.add_image(video_3D[:,:,:,:,1],name='green',colormap = 'green',blending=\"additive\", scale=[z_renorm,1,1])\n",
    "viewer.add_image(video_3D[:,:,:,:,2],name='blue',colormap = 'blue',blending=\"additive\", scale=[z_renorm,1,1])\n",
    "viewer.add_tracks(tracks[['TRACK_ID','POSITION_T','POSITION_Z','POSITION_Y','POSITION_X']].values, name=\"TRACK_IDs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "create_track_array_video(working_directory, track_array_filename, video_3D, \n",
    "                             tracks, crop_pad, xy_pixel_size, z_pixel_size)#, homography = my_homography)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Track Array bg-correction one-by-one: best-z projection + 2D disk/donut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Just in case you want to update trackArrayTools without having to restart Kernel\n",
    "#del sys.modules['trackArrayTools']  # Use this if you are coding new class methods and want to reread trackArrayTools.py file\n",
    "#from trackArrayTools import *\n",
    "\n",
    "# Choose which track array you want to work with:\n",
    "working_directory ='C:/Users/tim_s/OneDrive - Colostate/Stasevich Lab/Our papers/Ago2Tethering/TimFastTrackAnalysis/'\n",
    "track_array_filename = 'Tracks_TA02_90m_crop_pad_5.tif'\n",
    "\n",
    "# The corresponding tracking file should be in the same directory and have the following filename: \n",
    "track_filename = track_array_filename[:-15] + '.csv'\n",
    "\n",
    "# Read in the track array video \n",
    "track_array_vid = imread(working_directory + track_array_filename)  # Read in track array .tif file\n",
    "\n",
    "# Read in tracks as a \"dataframes (df)\"\n",
    "track_array_df = pd.read_csv(working_directory + track_filename)\n",
    "\n",
    "# Make sure color channels are the last dimension of the track array\n",
    "dims = list(track_array_vid.shape)\n",
    "if len(dims) != 3:     # check if just a single channel video\n",
    "    n_channels = min(dims)\n",
    "    n_channels_index = dims.index(n_channels)\n",
    "    track_array_vid = np.moveaxis(track_array_vid,n_channels_index,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Step 0: Create the track array object:\n",
    "ta = TrackArray(track_array_vid, track_array_df, crop_pad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Step 0.5: check if z's are offset in different channels\n",
    "my_offset = [0,0,0]  ### For 3-color, could be [0,-1,-1]; BE CAREFUL, THIS WILL MAKE A MASK THAT IS SHIFTED IN Z FOR BLUE AND GREEN!!!\n",
    "capsule_mask = ta.capsule_mask(crop_pad,crop_pad,2,1,1,z_offset=my_offset)\n",
    "arr_bg = ta.local_background_subtract(ta.arr,capsule_mask)\n",
    "\n",
    "# Check with napari\n",
    "max = np.max(arr_bg,axis=(0,1,2)) # find max intensities for setting intensity range\n",
    "my_range = [[0,max[ch]] for ch in np.arange(len(max))]\n",
    "napari_viewer(arr_bg,[z_renorm,1,1],int_range=my_range,layer=[capsule_mask[:,:,:,0],capsule_mask[:,:,:,1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Step 1: Best-z projection using offset from above\n",
    "my_best_z_masks = ta.best_z_mask(1,1,z_offset = my_offset) # best-z mask w/ offset\n",
    "best_z = ta.mask_projection(np.clip(ta.arr,0,1000000), my_best_z_masks) # best-z projection; clip to make sure data is +\n",
    "\n",
    "# Check with napari\n",
    "max = np.max(best_z,axis=(0,1)) # find max intensities for setting intensity range\n",
    "my_range = [[0,max[ch]] for ch in np.arange(len(max))]\n",
    "napari_viewer(best_z,[1,1],int_range=my_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Step 2: Subtract background in donut rings from max projection  \n",
    "best_z_bg = ta.local_background_subtract(best_z,ta.donut_mask_2D(5,1))\n",
    "\n",
    "# Check with napari and show donut mask\n",
    "max = np.max(best_z_bg,axis=(0,1)) # find max intensities for setting intensity range\n",
    "my_range = [[0,max[ch]] for ch in np.arange(len(max))]\n",
    "napari_viewer(best_z_bg,[1,1],int_range=my_range,layer=[ta.donut_mask_2D(5,1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Output background-subtracted and max-z projected track array \n",
    "output_filename_path = working_directory + track_array_filename[0:-4] + '_bestz_bg-sub.tif'\n",
    "io.imsave(output_filename_path,\n",
    "        best_z_bg, \n",
    "        resolution=(1/xy_pixel_size,1/xy_pixel_size))\n",
    "output_filename_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
